{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb74c8f9",
   "metadata": {},
   "source": [
    "# Plan ðŸ§­\n",
    "##### Choose the most critical metric for RAG for my use case (banking chatbot)\n",
    "1. relevancy\n",
    "2. groundedness\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884a4d46",
   "metadata": {},
   "source": [
    "## Relevancy evaluation\n",
    "\n",
    "#### Questions\n",
    "- what is relevancy in LLM context?\n",
    "- how to measure it?\n",
    "- what are the common approaches?\n",
    "- what are the common pitfalls?\n",
    "- what are the best practices?\n",
    "- how to implement it?\n",
    "- how to validate it?\n",
    "- how to benchmark it?\n",
    "- how to improve it?\n",
    "\n",
    "#### 1. Embedding based relevancy evaluator \n",
    "\n",
    "- To check relevancy, we can use cosine similarity between embeddings of the question and the answer.\n",
    "- We can use OpenAI's embedding model to generate embeddings for both the question and the answer.\n",
    "- Then, we can calculate the cosine similarity between the two embeddings.\n",
    "- If the cosine similarity is above a certain threshold, we can consider the answer to be relevant to the question.\n",
    "- We can use the following steps to implement this:\n",
    "    - Generate embeddings for the question and the answer using OpenAI's embedding model\n",
    "    - Calculate the cosine similarity between the two embeddings\n",
    "#### 2. LLM-as-a-judge evaluator\n",
    "\n",
    "- We can use a language model to evaluate the relevancy of the answer to the question\n",
    "- by prompting the model with the question and the answer and asking it to rate the relevancy on a scale of 1 to 10.\n",
    "- We can use the following steps to implement this:\n",
    "    - Create a prompt that includes the question and the answer\n",
    "    - Use the language model to generate a response to the prompt\n",
    "    - Parse the response to extract the relevancy rating\n",
    "\n",
    "## Sources ðŸ“š\n",
    "### Microsoft\n",
    "- https://github.com/Azure/azure-sdk-for-python/tree/azure-ai-evaluation_1.0.0b5/sdk/evaluation/azure-ai-evaluation\n",
    "- https://github.com/Azure/azure-sdk-for-python/blob/azure-ai-evaluation_1.0.0b5/sdk/evaluation/azure-ai-evaluation/azure/ai/evaluation/_evaluators/_relevance/relevance.prompty\n",
    "- Azure AI search tailored relevance evaluator - https://github.com/Azure-Samples/azureai-samples/blob/main/scenarios/evaluate/Supported_Evaluation_Metrics/RAG_Evaluation/Optimize_RAG_with_Document_Retrieval_Evaluator.ipynb\n",
    "\n",
    "### Ragas\n",
    "- https://docs.ragas.io/en/stable/getstarted/rag_eval/#load-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b541c204",
   "metadata": {},
   "source": [
    "## Groundedness\n",
    "\n",
    "#### 1. Entity-based groundedness evaluator\n",
    "- To check groundedness, we can extract entities from the answer and check if they are present in the context.\n",
    "- We can use a named entity recognition (NER) model to extract entities from the answer.\n",
    "- Then, we can check if the extracted entities are present in the context.\n",
    "- If a certain percentage of the extracted entities are present in the context, we can consider the answer to be grounded.\n",
    "- We can use the following steps to implement this:\n",
    "    - Use a NER model to extract entities from the answer\n",
    "    - Check if the extracted entities are present in the context\n",
    "#### 2. LLM-as-a-judge evaluator\n",
    "- We can use a language model to evaluate the groundedness of the answer by prompting the model with the context and the answer\n",
    "- and asking it to rate the groundedness on a scale of 1 to 10.\n",
    "- We can use the following steps to implement this:\n",
    "    - Create a prompt that includes the context and the answer\n",
    "    - Use the language model to generate a response to the prompt\n",
    "    - Parse the response to extract the groundedness rating"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
