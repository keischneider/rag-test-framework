{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "472b5240",
   "metadata": {},
   "source": [
    "☝️\n",
    "“LLMs are better at discriminating between options. Therefore, evaluations should focus on tasks like pairwise comparisons, classification, or scoring against specific criteria instead of open-ended generation. Aligning evaluation methods with LLMs' strengths in comparison leads to more reliable assessments of LLM outputs or model comparisons.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d95d7c",
   "metadata": {},
   "source": [
    "### How can I measure the price of each openai API call (including embeddings)?  \n",
    "*look into openai evals library: https://platform.openai.com/docs/guides/evals?api-mode=responses*\n",
    "### Sources\n",
    "https://platform.openai.com/docs/api-reference/evals  \n",
    "https://cookbook.openai.com/examples/question_answering_using_embeddings  \n",
    "https://cookbook.openai.com/examples/evaluation/use-cases/regression  \n",
    "https://platform.openai.com/docs/guides/evals-design?api-mode=responses  \n",
    "https://platform.openai.com/docs/guides/graders  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5a0a22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run response: {\n",
      "  \"reward\": 1.0,\n",
      "  \"metadata\": {\n",
      "    \"name\": \"my_score_model\",\n",
      "    \"type\": \"score_model\",\n",
      "    \"errors\": {\n",
      "      \"formula_parse_error\": false,\n",
      "      \"sample_parse_error\": false,\n",
      "      \"sample_parse_error_details\": null,\n",
      "      \"truncated_observation_error\": false,\n",
      "      \"unresponsive_reward_error\": false,\n",
      "      \"invalid_variable_error\": false,\n",
      "      \"invalid_variable_error_details\": null,\n",
      "      \"other_error\": false,\n",
      "      \"python_grader_server_error\": false,\n",
      "      \"python_grader_server_error_type\": null,\n",
      "      \"python_grader_runtime_error\": false,\n",
      "      \"python_grader_runtime_error_details\": null,\n",
      "      \"model_grader_server_error\": false,\n",
      "      \"model_grader_refusal_error\": false,\n",
      "      \"model_grader_refusal_error_details\": null,\n",
      "      \"model_grader_parse_error\": false,\n",
      "      \"model_grader_parse_error_details\": null,\n",
      "      \"model_grader_exceeded_max_tokens_error\": false,\n",
      "      \"model_grader_server_error_details\": null,\n",
      "      \"endpoint_grader_internal_error\": false,\n",
      "      \"endpoint_grader_internal_error_details\": null,\n",
      "      \"endpoint_grader_server_error\": false,\n",
      "      \"endpoint_grader_server_error_details\": null,\n",
      "      \"endpoint_grader_safety_check_error\": false\n",
      "    },\n",
      "    \"execution_time\": 4.934762239456177,\n",
      "    \"scores\": {},\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 592,\n",
      "      \"total_tokens\": 1002,\n",
      "      \"completion_tokens\": 410,\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"sampled_model_name\": \"o4-mini-2025-04-16\"\n",
      "  },\n",
      "  \"sub_rewards\": {},\n",
      "  \"model_grader_token_usage_per_model\": {\n",
      "    \"o4-mini-2025-04-16\": {\n",
      "      \"prompt_tokens\": 592,\n",
      "      \"total_tokens\": 1002,\n",
      "      \"completion_tokens\": 410,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# get the API key from environment\n",
    "api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "\n",
    "# define a dummy grader for illustration purposes\n",
    "grader = {\n",
    "   \"type\": \"score_model\",\n",
    "   \"name\": \"my_score_model\",\n",
    "   \"input\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a text analytics, who evaluates relevance of an answer to a given question. You will be given a question and an answer, the goal is to deeply analyse it and come up with a score from 0 to 1, where 0 means the answer is completely irrelevant, and 1 - is the answer is absolutely relevant.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Here is the question and answer to evaluate: Question: {{ item.input }} Answer: {{ sample.output_text }}\"\n",
    "        }\n",
    "   ],\n",
    "   \"pass_threshold\": 0.5,\n",
    "   \"model\": \"o4-mini-2025-04-16\",\n",
    "   \"range\": [0, 1],\n",
    "   \"sampling_params\": {\n",
    "       \"max_completions_tokens\": 32768,\n",
    "       \"top_p\": 1,\n",
    "       \"reasoning_effort\": \"medium\"\n",
    "   },\n",
    "}\n",
    "\n",
    "# validate the grader\n",
    "payload = {\"grader\": grader}\n",
    "response = requests.post(\n",
    "    \"https://api.openai.com/v1/fine_tuning/alpha/graders/validate\",\n",
    "    json=payload,\n",
    "    headers=headers\n",
    ")\n",
    "# print(\"validate response:\", response.text)\n",
    "\n",
    "# run the grader with a test reference and sample\n",
    "payload = {\n",
    "  \"grader\": grader,\n",
    "  \"item\": {\n",
    "     \"input\": \"I see a charge on my credit card for $2,500 to \\\"ElectroMax\\\" on 2025-08-01 that I don't recognize. The card is 4111 1111 1111 1111. Please investigate and take action.\"\n",
    "  },\n",
    "  \"model_sample\": \"Immediate response (sensitive action): 1) Confirm identity: ask customer to verify full name, date of birth (30), and last 4 of account (6789) or last 4 of card (1111). 2) While verifying, place an immediate temporary block on card number 4111 1111 1111 1111 to prevent further charges. 3) Create a fraud case with severity: high; record: merchant \\\"ElectroMax\\\", amount $2,500, date 2025-08-01, transaction ID (if available). 4) Provisionally credit the $2,500 pending investigation (explain provisional credit policy and timeline). 5) Start dispute process: request client-supplied evidence (receipt, photos, merchant communication), and confirm whether customer wants a replacement card issued. 6) Notify customer via their preferred contact_method (email: john.doe@example.com) and inform that two-factor authentication will be required for any account changes. 7) Next steps for customer: respond with a copy/photo of the cardholder’s ID and a short written statement if prompted, confirm whether they made any recent authorized transactions or gave card to a family member. 8) Internal actions: escalate to fraud team, monitor account 123456789 and routing 987654321 for suspicious transfers, log event with timestamp, agent ID, and actions taken. Estimated resolution time: 7–10 business days for full investigation; provisional credit may take 3–5 business days. If urgent, provide phone support option to +1-202-555-0199.\"\n",
    "}\n",
    "response = requests.post(\n",
    "    \"https://api.openai.com/v1/fine_tuning/alpha/graders/run\",\n",
    "    json=payload,\n",
    "    headers=headers\n",
    ")\n",
    "\n",
    "print(\"run response:\", response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
